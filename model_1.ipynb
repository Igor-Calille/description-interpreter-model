{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\igorm\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n",
      "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]\n",
      "Requirement already satisfied: torch in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.41.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\igorm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "\n",
    "!pip install torch \n",
    "\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open('output.json', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "inputs = [item['input'] for item in data]\n",
    "outputs = [\n",
    "    f\"code: {item['output']['catalog_catalog.code']} description: {item['output']['catalog_catalog.description']} \"\n",
    "    f\"full_description: {item['output']['catalog_catalog.full_description']} similar_parts: {item['output']['catalog_catalog.similar_parts']} \"\n",
    "    f\"application_table: {item['output']['catalog_catalog.application_table']} brand_producer: {item['output']['catalog_catalog.brand_producer']}\"\n",
    "    for item in data\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, test_inputs, train_outputs, test_outputs = train_test_split(inputs, outputs, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\igorm\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "model_name = \"unicamp-dl/ptt5-base-portuguese-vocab\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "class T5Dataset(Dataset):\n",
    "    def __init__(self, inputs, outputs, tokenizer, max_length=512):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_text = self.inputs[idx]\n",
    "        output_text = self.outputs[idx]\n",
    "\n",
    "        # Tokenização\n",
    "        input_encoding = self.tokenizer(\n",
    "            input_text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt'\n",
    "        )\n",
    "        output_encoding = self.tokenizer(\n",
    "            output_text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids = input_encoding['input_ids'].squeeze()\n",
    "        attention_mask = input_encoding['attention_mask'].squeeze()\n",
    "        labels = output_encoding['input_ids'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels\n",
    "        }\n",
    "    \n",
    "train_dataset = T5Dataset(train_inputs, train_outputs, tokenizer)\n",
    "test_dataset = T5Dataset(test_inputs, test_outputs, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results directory exists: True\n",
      "Logs directory exists: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [07:31<00:00, 75.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 451.393, 'train_samples_per_second': 0.04, 'train_steps_per_second': 0.013, 'train_loss': 34.14764912923177, 'epoch': 3.0}\n",
      "Modelo salvo em ./results/t5_model\n",
      "Tokenizador salvo em ./results/t5_tokenizer\n",
      "52182585 Lanterna Jeep Renegade Esquerdo 52182584 Marca: Jeep, Número de peça: 52182585, Lado: Esquerdo, Tipo de veículo: Carro/Caminhonete, DescriçãoPRODUTO NOVO E ORIGINAL PRONTA ENTREGA + NOTA FISCAL + GARANTIA LANTERNA LED TRASEIRA ESQUERDA, LADO MOTORISTA- PEÇA GENUÍNA MOPAR- IMAGEM REAL DA PEÇAAPLICAÇÃO:- JEEP RENEGADE 2022 / 2023CÓDIGO :52182584VALOR DO ANÚNCIO REFERENTE A UNIDADEESTAMOS A DISPOSIÇÃO - LOUVADO SEJA DEUSGarantia do vendedor: 3 meses\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "\n",
    "temp_dir = tempfile.gettempdir()\n",
    "results_dir = os.path.join(temp_dir, 'results')\n",
    "logs_dir = os.path.join(temp_dir, 'logs')\n",
    "\n",
    "\n",
    "def ensure_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "ensure_dir(results_dir)\n",
    "ensure_dir(logs_dir)\n",
    "\n",
    "print(f\"Results directory exists: {os.path.exists(results_dir)}\")\n",
    "print(f\"Logs directory exists: {os.path.exists(logs_dir)}\")\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=results_dir,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=logs_dir,\n",
    "    logging_steps=10,\n",
    "    save_steps=10,\n",
    "    evaluation_strategy=\"steps\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model_save_path = \"./results/t5_model\"\n",
    "tokenizer_save_path = \"./results/t5_tokenizer\"\n",
    "\n",
    "\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "os.makedirs(tokenizer_save_path, exist_ok=True)\n",
    "\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(tokenizer_save_path)\n",
    "\n",
    "print(f\"Modelo salvo em {model_save_path}\")\n",
    "print(f\"Tokenizador salvo em {tokenizer_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'catalog_catalog.code': '', 'catalog_catalog.full_description': '', 'catalog_catalog.description': '', 'catalog_catalog.similar_parts': 'N/D', 'catalog_catalog.application_table': '', 'catalog_catalog.brand_producer': 'JEEP'}\n"
     ]
    }
   ],
   "source": [
    "def generate_output(input_text):\n",
    "\n",
    "    inputs = tokenizer.encode(\"translate English to English: \" + input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "\n",
    "    outputs = model.generate(inputs, max_length=512, num_beams=4, early_stopping=True)\n",
    "    \n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    output_dict = {\n",
    "        \"catalog_catalog.code\": \"\",\n",
    "        \"catalog_catalog.full_description\": \"\",\n",
    "        \"catalog_catalog.description\": \"\",\n",
    "        \"catalog_catalog.similar_parts\": \"N/D\",\n",
    "        \"catalog_catalog.application_table\": \"\",\n",
    "        \"catalog_catalog.brand_producer\": \"JEEP\"\n",
    "    }\n",
    "    \n",
    "    output_values = output_text.split(\",\")\n",
    "    if len(output_values) == 5:\n",
    "        output_dict[\"catalog_catalog.code\"] = output_values[0].strip()\n",
    "        output_dict[\"catalog_catalog.full_description\"] = output_values[1].strip()\n",
    "        output_dict[\"catalog_catalog.description\"] = output_values[2].strip()\n",
    "        output_dict[\"catalog_catalog.application_table\"] = output_values[3].strip()\n",
    "        output_dict[\"catalog_catalog.brand_producer\"] = output_values[4].strip()\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "input_text = \"735598946\\tCapa Espelho Retrovisor Direito Renegade 2019\\tMarca: Jeep, Número de peça: 735598946, Modelo: RENEGADE  Anos: 2021, 2020, 2019, 2018, 2017, 2016, 2015..., Tipo de veículo: Carro/Caminhonete, Lado: Direito, Material: MTR, Origem: Brasil, \\tDescriçãoSe aplica em:•JEEP Renegade de 2015 a 2021Codigos:735598946Peca Genuina, com nota fiscal e garantia!Em Caso de Duvidas, Consulte Nossos Especialistas:Para evitarmos erros e possiveis devolucoes, em caso de duvidas, informe sempre o Chassi Completo do seu veiculo no campo de perguntas. Assim poderemos verificar diretamente na fabrica a correta aplicacao para o seu veiculo.Seguranca:As Pecas Originais e Genuinas sao projetadas sob medida para cada modelo de automovel, elas sao a garantia de seguranca para voce. Todos nossos produtos sao originais e vao com nota fiscal.Suporte:- Temos Equipe de Atendimento e Suporte Tecnico Especializado a sua Disposicao.Saga, casa de amigos!Marca: Aplicacao universal ou nao informada, se tiver duvida, nos faca uma pergunta.________________Codigo:735598946________________ATENCAO:- Antes de efetuar a compra tire todas suas duvidas no campo perguntas.- Mantenha seus dados e enderecos atualizados no site do Mercado Livre.- Se o Mercado Envios nao entregar seu produto,seu pagamento sera devolvido automaticamente pelo Mercado Livre.- Temos carrinho de compras, adicione varios produtos e economize no Frete.- Todos os produtos anunciados estao disponiveis em nosso estoque.- Aceitamos devolucoes apenas com a embalagem Original e Nota Fiscal. - Devido a alteracao nas politicas do Mercado Livre o frete gratis esta sujeito ao peso, preco e distancia do envio.________________SUPORTE E HORARIOS DE ATENDIMENTO:- Temos Equipe de Atendimento e Suporte Tecnico Especializado a Disposicao.- Atendimento de Seg. a Sex. das 8h00 as 18h00 e Sab. 8h00 as 12h00.________________Garantia do vendedor: 90 dias\"\n",
    "output = generate_output(input_text)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
